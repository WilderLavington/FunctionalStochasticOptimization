{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb\n",
    "api = wandb.Api(timeout=180)\n",
    "import os\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import itertools\n",
    "import  matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import itertools\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fa6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER='wilderlavington' \n",
    "PROJECT='FunctionalOptimization'\n",
    "SUMMARY_FILE='aistats_fig2.csv' \n",
    "K=1\n",
    "try:\n",
    "    os.makedirs(\"plots/aistats/\")\n",
    "except FileExistsError:\n",
    "    print(\"File already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wandb_summary(label = 'workshop-fig2'):\n",
    "    \"\"\"\n",
    "    Download a summary of all runs on the wandb project\n",
    "    \"\"\"\n",
    "    runs = api.runs(USER+'/'+PROJECT, per_page=1000000000)\n",
    "    summary_list, config_list, name_list, id_list, commits = [], [], [], [], []\n",
    "    assert len([run for run in runs]) \n",
    "    for run in tqdm(runs):\n",
    "        run = api.run(USER+'/'+PROJECT+\"/\"+run.id)\n",
    "        conf = {k: v for k, v in run.config.items()}\n",
    "        if 'label' in conf.keys(): \n",
    "            if conf['label'] == label:\n",
    "                summary_list.append(run.summary._json_dict)\n",
    "                config_list.append(conf)\n",
    "                name_list.append(run.name)\n",
    "                id_list.append(run.id)\n",
    "                commits.append(run.commit)\n",
    "        else:\n",
    "            pass\n",
    "    assert len(summary_list)\n",
    "    commits_df = pd.DataFrame.from_records(commits)\n",
    "    summary_df = pd.DataFrame.from_records(summary_list)\n",
    "    config_df = pd.DataFrame.from_records(config_list)\n",
    "    name_df = pd.DataFrame({\"name\": name_list, \"id\": id_list})\n",
    "    all_df = pd.concat([name_df, config_df, summary_df, commits_df], axis=1)\n",
    "    Path('logs/wandb_data/').mkdir(parents=True, exist_ok=True)\n",
    "    all_df.to_csv('logs/wandb_data/'+SUMMARY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572f4f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 9723/9723 [30:18<00:00,  5.35it/s]\n"
     ]
    }
   ],
   "source": [
    "download_wandb_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7f7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_wandb_records():\n",
    "    \"\"\"\n",
    "    Download data for all runs in summary file\n",
    "    \"\"\"\n",
    "    # load it all in and clean it up\n",
    "    runs_df = pd.read_csv('logs/wandb_data/'+SUMMARY_FILE, header=0, squeeze=True)\n",
    "    runs_df = runs_df.loc[:,~runs_df.columns.duplicated()]\n",
    "    columns_of_interest = ['avg_loss', 'optim_steps', 'grad_norm', 'time_elapsed', \\\n",
    "             'grad_evals', 'function_evals', 'eta', 'inner_steps', 'eta_scale']\n",
    "    # set which columns we will store for vizualization\n",
    "    list_of_dataframes = []\n",
    "    # iterate through all runs to create individual databases\n",
    "    for ex in tqdm(range(len(runs_df)), leave=False):\n",
    "        # get the associated runs\n",
    "        try:\n",
    "            run = api.run(USER+'/'+PROJECT+'/'+runs_df.loc[runs_df.iloc[ex,0],:]['id'])\n",
    "            run_df = []\n",
    "            # iterate through all rows in online database\n",
    "            base_info = {}\n",
    "            for key in runs_df.loc[runs_df.iloc[ex,0],:].keys():\n",
    "                base_info.update({key:runs_df.loc[runs_df.iloc[ex,0],:][key]})\n",
    "            for i, row in run.history().iterrows():\n",
    "                row_info = deepcopy(base_info)\n",
    "                row_info.update({key:row[key] for key in columns_of_interest if key in row.keys()})\n",
    "                run_df.append(row_info)\n",
    "            # convert format to dataframe and add to our list\n",
    "            list_of_dataframes.append(pd.DataFrame(run_df))\n",
    "        except:\n",
    "            pass\n",
    "    # combine and then store\n",
    "    wandb_records = pd.concat(list_of_dataframes)\n",
    "    wandb_records.to_csv('logs/wandb_data/__full__'+SUMMARY_FILE)\n",
    "    # return single data frame for vizualization\n",
    "    return wandb_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854009e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>c</th>\n",
       "      <th>m</th>\n",
       "      <th>algo</th>\n",
       "      <th>loss</th>\n",
       "      <th>seed</th>\n",
       "      <th>group</th>\n",
       "      <th>label</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>deft-flower-2384</td>\n",
       "      <td>o7v5dup5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>3</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>f</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>deft-flower-2384</td>\n",
       "      <td>o7v5dup5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>3</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>f</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>deft-flower-2384</td>\n",
       "      <td>o7v5dup5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>3</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>f</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>deft-flower-2384</td>\n",
       "      <td>o7v5dup5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>3</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>f</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>deft-flower-2384</td>\n",
       "      <td>o7v5dup5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>3</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>f</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>134</td>\n",
       "      <td>jumping-gorge-2</td>\n",
       "      <td>1a1pafrm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>1</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>134</td>\n",
       "      <td>jumping-gorge-2</td>\n",
       "      <td>1a1pafrm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>1</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>134</td>\n",
       "      <td>jumping-gorge-2</td>\n",
       "      <td>1a1pafrm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>1</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>134</td>\n",
       "      <td>jumping-gorge-2</td>\n",
       "      <td>1a1pafrm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>1</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>134</td>\n",
       "      <td>jumping-gorge-2</td>\n",
       "      <td>1a1pafrm</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>SGD_FMDOpt</td>\n",
       "      <td>MSELoss</td>\n",
       "      <td>1</td>\n",
       "      <td>AIstats_narval</td>\n",
       "      <td>workshop-fig2</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61581 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0              name        id    c   m        algo     loss  \\\n",
       "0             0  deft-flower-2384  o7v5dup5  0.1  10  SGD_FMDOpt  MSELoss   \n",
       "1             0  deft-flower-2384  o7v5dup5  0.1  10  SGD_FMDOpt  MSELoss   \n",
       "2             0  deft-flower-2384  o7v5dup5  0.1  10  SGD_FMDOpt  MSELoss   \n",
       "3             0  deft-flower-2384  o7v5dup5  0.1  10  SGD_FMDOpt  MSELoss   \n",
       "4             0  deft-flower-2384  o7v5dup5  0.1  10  SGD_FMDOpt  MSELoss   \n",
       "..          ...               ...       ...  ...  ..         ...      ...   \n",
       "495         134   jumping-gorge-2  1a1pafrm  0.1   2  SGD_FMDOpt  MSELoss   \n",
       "496         134   jumping-gorge-2  1a1pafrm  0.1   2  SGD_FMDOpt  MSELoss   \n",
       "497         134   jumping-gorge-2  1a1pafrm  0.1   2  SGD_FMDOpt  MSELoss   \n",
       "498         134   jumping-gorge-2  1a1pafrm  0.1   2  SGD_FMDOpt  MSELoss   \n",
       "499         134   jumping-gorge-2  1a1pafrm  0.1   2  SGD_FMDOpt  MSELoss   \n",
       "\n",
       "     seed           group          label  ... 30  31  32 33  34 35  36 37  38  \\\n",
       "0       3  AIstats_narval  workshop-fig2  ...  1   8   f  7   1  b   7  b   4   \n",
       "1       3  AIstats_narval  workshop-fig2  ...  1   8   f  7   1  b   7  b   4   \n",
       "2       3  AIstats_narval  workshop-fig2  ...  1   8   f  7   1  b   7  b   4   \n",
       "3       3  AIstats_narval  workshop-fig2  ...  1   8   f  7   1  b   7  b   4   \n",
       "4       3  AIstats_narval  workshop-fig2  ...  1   8   f  7   1  b   7  b   4   \n",
       "..    ...             ...            ...  ... ..  ..  .. ..  .. ..  .. ..  ..   \n",
       "495     1  AIstats_narval  workshop-fig2  ...  a   8   d  8   2  2   a  f   6   \n",
       "496     1  AIstats_narval  workshop-fig2  ...  a   8   d  8   2  2   a  f   6   \n",
       "497     1  AIstats_narval  workshop-fig2  ...  a   8   d  8   2  2   a  f   6   \n",
       "498     1  AIstats_narval  workshop-fig2  ...  a   8   d  8   2  2   a  f   6   \n",
       "499     1  AIstats_narval  workshop-fig2  ...  a   8   d  8   2  2   a  f   6   \n",
       "\n",
       "     39  \n",
       "0     5  \n",
       "1     5  \n",
       "2     5  \n",
       "3     5  \n",
       "4     5  \n",
       "..   ..  \n",
       "495   1  \n",
       "496   1  \n",
       "497   1  \n",
       "498   1  \n",
       "499   1  \n",
       "\n",
       "[61581 rows x 93 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_wandb_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ea348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(array, k):\n",
    "    array = np.array(array)\n",
    "    new_array = deepcopy(array)\n",
    "    # print(array[max(0,i-k):i] )\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) != 'nan':\n",
    "            avg_list = [val for val in array[max(0,i-k):i+1] if str(val) != 'nan']\n",
    "            new_array[i] = sum(avg_list) / len(avg_list)\n",
    "    return new_array\n",
    "def format_dataframe(records, id_subfields={}, avg_subfields=['seed'],\n",
    "            max_subfields=['log_lr', 'eta_schedule', 'c'],\n",
    "            x_col='optim_steps', y_col='avg_loss'):\n",
    "    #\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    max_subfields = [m for m in max_subfields if m not in id_subfields.keys()]\n",
    "    for key in id_subfields:  \n",
    "        records = records.loc[records[key] == id_subfields[key]] \n",
    "    records['function_evals+grad_evals'] = records['function_evals']+records['grad_evals']\n",
    "    if not len(records):\n",
    "        return None\n",
    "    # remove nans\n",
    "    records = records[records[y_col].notna()]\n",
    "    important_cols = list(set(avg_subfields+max_subfields+\\\n",
    "        list(id_subfields.keys())+[x_col, y_col, 'optim_steps']))\n",
    "    # remove redundant information\n",
    "    records = records[important_cols]\n",
    "    # average over avg_subfields\n",
    "    records = records.drop(avg_subfields, axis=1)\n",
    "    # group over averaging field\n",
    "    gb = list(set(list(max_subfields+list(id_subfields.keys())+[x_col, 'optim_steps'])))\n",
    "    # only look at final optim steps\n",
    "    last_mean_records = records.loc[records['optim_steps'] == records['optim_steps'].max()]\n",
    "    # get the best record\n",
    "    best_record = last_mean_records[last_mean_records[y_col] == last_mean_records[y_col].min()]\n",
    "    # find parameters of the best record\n",
    "    merge_on = list(set(gb)-set(['optim_steps', x_col, y_col]))\n",
    "    merge_on = [ x for x in merge_on if x in best_record.columns.values]\n",
    "    best_records = pd.merge(best_record[merge_on], records, on=merge_on,how='left')\n",
    "    final_records = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].mean()\n",
    "    final_records[y_col+'25'] = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].quantile(0.25)[y_col]\n",
    "    final_records[y_col+'75'] = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].quantile(0.75)[y_col]\n",
    "    final_records = final_records.sort_values(x_col, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "    # smooth outputs \n",
    "    final_records[y_col+'75'] = smooth(final_records[y_col+'75'],K)\n",
    "    final_records[y_col+'25'] = smooth(final_records[y_col+'25'],K)\n",
    "    final_records[y_col] = smooth(final_records[y_col],K) \n",
    "    # return \n",
    "    return final_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b7836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(proc_df, x, y, ax, label, linestyle='solid', color=None, x_max=5000000):\n",
    "    low_order_idx = (torch.tensor(proc_df[x].values) < x_max).nonzero().reshape(-1)\n",
    "    if label:\n",
    "        ax.plot(torch.tensor(proc_df[x].values[low_order_idx]), \n",
    "                torch.tensor(proc_df[y].values[low_order_idx]), \n",
    "                label=label, linestyle=linestyle, color=color, alpha=0.8,\n",
    "                linewidth=4)\n",
    "    else:\n",
    "        ax.plot(torch.tensor(proc_df[x].values[low_order_idx]), \n",
    "                torch.tensor(proc_df[y].values[low_order_idx]), \n",
    "                label='_nolegend_', linestyle=linestyle, color=color, alpha=0.8,\n",
    "                linewidth=4)\n",
    "    ax.fill_between(torch.tensor(proc_df[x].values)[low_order_idx],\n",
    "            torch.tensor(proc_df[y+'75'].values)[low_order_idx],\n",
    "            torch.tensor(proc_df[y+'25'].values)[low_order_idx], \n",
    "            alpha = 0.4, label='_nolegend_', linestyle=linestyle, color=color)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd9f1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_figure_1a(loss, schedule, wandb_records):\n",
    "    \n",
    "    # base info   \n",
    "    dataset_names = ['mfac']\n",
    "    batch_sizes = [25, 125, 625]\n",
    "    m = [1, 5, 10, 20]\n",
    "    x = 'optim_steps'\n",
    "    y = 'grad_norm'\n",
    "    \n",
    "    # init plots \n",
    "    fig, axs = plt.subplots(len(dataset_names), len(batch_sizes)+1, figsize=(16, 8))\n",
    "    colors = mpl.cm.Set1.colors   # Qualitative colormap\n",
    "    colormap = {'SGD': '#44AA99' , 'SLS': '#DDCC77'}\n",
    "    colormap.update({'SSO-1':  '#CC6677' ,  'SSO-5': '#AA4499', 'SSO-10': '#882255' , 'SSO-20': '#332288'})\n",
    "    algorithms = ['SGD', 'SLS'] + ['SSO-'+str(m_) for m_ in m]\n",
    "#     plt.title('Comparison of SGD, SLS, Functional-SGD: '+loss)\n",
    "    label_map = {x:'Optimization-Steps', y:'Gradient-Norm'}\n",
    "    \n",
    "    # now add in the lines to each of the plots \n",
    "    for row, dataset_name in enumerate(dataset_names):\n",
    "        \n",
    "        # figure out axis automatically \n",
    "        x_max = 0 \n",
    "\n",
    "        # SLS\n",
    "        proc_df = format_dataframe(wandb_records,\n",
    "            id_subfields={'fullbatch': 1,  \n",
    "            'use_optimal_stepsize': 0, 'loss': loss, 'algo': 'LSOpt',\n",
    "            'eta_schedule': schedule, 'dataset_name': dataset_name},\n",
    "            x_col=x , y_col=y) \n",
    "        if proc_df is not None:\n",
    "            x_max = max(proc_df[x].values.max(), x_max)\n",
    "            axs[row][-1] = generate_plot(proc_df, x, y, axs[row][-1], label='SLS', \n",
    "                                         linestyle='dashed', color=colormap['SLS'])\n",
    "        else:\n",
    "            print('missing SLS  ', dataset_name, 'full-batch')\n",
    "\n",
    "        # SGD\n",
    "        proc_df = format_dataframe(wandb_records,\n",
    "            id_subfields={'fullbatch': 1,  \n",
    "            'use_optimal_stepsize': 0, 'loss': loss, 'algo': 'SGD',\n",
    "            'eta_schedule': schedule, 'dataset_name': dataset_name},\n",
    "            x_col=x , y_col=y) \n",
    "        if proc_df is not None: \n",
    "            x_max = max(proc_df[x].values.max(), x_max)\n",
    "            axs[row][-1] = generate_plot(proc_df, x, y, axs[row][-1], label='SGD', \n",
    "                                         linestyle='dashed', color=colormap['SGD'])\n",
    "        else:\n",
    "            print('missing SGD  ', dataset_name, 'full-batch')\n",
    "        # FMDopt theoretical \n",
    "        for m_ in m:\n",
    "            # create parsed info \n",
    "            proc_df = format_dataframe(wandb_records, \n",
    "                id_subfields={'fullbatch': 1,   \n",
    "                    'use_optimal_stepsize': 0, \n",
    "                    'loss': loss, 'algo': 'SGD_FMDOpt', 'm': m_,\n",
    "                    'eta_schedule': schedule, 'dataset_name': dataset_name}, \n",
    "                     avg_subfields=['seed'], max_subfields=['c'],\n",
    "                x_col=x, y_col=y)\n",
    "            if proc_df is not None:\n",
    "                x_max = max(proc_df[x].values.max(), x_max)\n",
    "                axs[row][-1] = generate_plot(proc_df, x, y, axs[row][-1],  \\\n",
    "                                        label='SSO-'+str(m_), linestyle='solid', color=colormap['SSO-'+str(m_)])\n",
    "            else:\n",
    "                print('missing FMDopt  ', m_, dataset_name, 'full-batch')\n",
    "                \n",
    "        axs[row][-1].grid()     \n",
    "        axs[row][-1].set_yscale(\"log\")\n",
    "        axs[row][-1].set_xscale(\"log\")\n",
    "\n",
    "        # mini-batch plots \n",
    "        for col, batch_size in enumerate(batch_sizes):\n",
    "            \n",
    "            # figure out axis automatically \n",
    "            x_max = 0 \n",
    "            \n",
    "            # SLS\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size,  #'_step': 499.0,\n",
    "                'use_optimal_stepsize': 0, 'loss': loss, 'algo': 'LSOpt',\n",
    "                'eta_schedule': schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            if proc_df is not None:\n",
    "                x_max = max(proc_df[x].values.max(), x_max)\n",
    "                axs[row][col] = generate_plot(proc_df, x, y, axs[row][col], label='SLS', \n",
    "                                             linestyle='dashed', color=colormap['SLS'])\n",
    "            else:\n",
    "                print('missing SLS  ', dataset_name, batch_size)\n",
    "            \n",
    "            # SGD\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size, '_step': 499.0,\n",
    "                'use_optimal_stepsize': 0, 'loss': loss, 'algo': 'SGD',\n",
    "                'eta_schedule': schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            if proc_df is not None: \n",
    "                x_max = max(proc_df[x].values.max(), x_max)\n",
    "                axs[row][col] = generate_plot(proc_df, x, y, axs[row][col], label='SGD', \n",
    "                                             linestyle='dashed', color=colormap['SGD'])\n",
    "            else:\n",
    "                print('missing SGD  ', dataset_name, batch_size)\n",
    "    \n",
    "            # FMDopt theoretical \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(wandb_records, \n",
    "                    id_subfields={'batch_size': batch_size,  \n",
    "                        'use_optimal_stepsize': 0, '_step': 499.0,\n",
    "                        'loss': loss, 'algo': 'SGD_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['c'],\n",
    "                    x_col=x, y_col=y)\n",
    "                if proc_df is not None:\n",
    "                    x_max = max(proc_df[x].values.max(), x_max)\n",
    "                    axs[row][col] = generate_plot(proc_df, x, y, axs[row][col], \\\n",
    "                                            label='SSO-'+str(m_), linestyle='solid', color=colormap['SSO-'+str(m_)])\n",
    "                else:\n",
    "                    print('missing FMDopt  ', m_, dataset_name, batch_size)\n",
    "            \n",
    "            axs[row][col].grid()    \n",
    "            axs[row][col].ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "            axs[row][col].yaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "            axs[row][col].set_yscale(\"log\")\n",
    "            axs[row][col].set_xscale(\"log\")\n",
    "            axs[0][col].set_title('batch_size: '+str(batch_size), fontsize=22)\n",
    "            axs[0][-1].set_title('full-batch', fontsize=22)\n",
    "            axs[row][-1].set_ylabel(dataset_name, fontsize=22)\n",
    "            axs[row][-1].yaxis.set_label_position(\"right\")\n",
    "            \n",
    "            axs[row][col].xaxis.set_minor_locator(mpl.ticker.LogLocator(base=10,numticks=100))\n",
    "            axs[row][col].xaxis.set_minor_formatter(mpl.ticker.NullFormatter()) \n",
    "        \n",
    "    # remaining format stuff  \n",
    "    handles = [mpatches.Patch(color=colormap[algo], label=algo) for algo in algorithms]\n",
    "    leg = fig.legend(handles=handles,\n",
    "           loc=\"lower center\",   # Position of legend\n",
    "           borderaxespad=1.65,    # Small spacing around legend box\n",
    "           # title=\"Algorithms\",  # Title for the legend\n",
    "           fontsize=18,\n",
    "           ncol=7, \n",
    "           bbox_to_anchor=(0.525, -0.12),\n",
    "           )\n",
    "    \n",
    "    plt.subplots_adjust(hspace=1.5)\n",
    "    plt.rcParams['figure.dpi'] = 400 \n",
    "#     plt.suptitle('Optimizer Comparison: '+loss, fontsize=28)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # fig.subplots_adjust(top=0.95) \n",
    "    # show / save\n",
    "    plt.savefig('plots/workshop-plot1-'+loss+'.pdf', bbox_inches='tight')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca46e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlavington/Desktop/mujoco_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3169: DtypeWarning: Columns (56,61,62,63,64,67,68,70,71,72,73,74,75,76,77,78,80,82,83,84,89,90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "wandb_records = pd.read_csv('logs/wandb_data/__full__'+SUMMARY_FILE, header=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4555686",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing SLS   mfac full-batch\n",
      "missing SGD   mfac full-batch\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'AxesSubplot' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_298851/328952058.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_figure_1a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSELoss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_records\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_298851/4011254733.py\u001b[0m in \u001b[0;36mgenerate_figure_1a\u001b[0;34m(loss, schedule, wandb_records)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mproc_df\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 axs[row][-1] = generate_plot(proc_df, x, y, axs[row][-1],  \\\n\u001b[0m\u001b[1;32m     63\u001b[0m                                         label='SSO-'+str(m_), linestyle='solid', color=colormap['SSO-'+str(m_)])\n\u001b[1;32m     64\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'AxesSubplot' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_figure_1a('MSELoss', 'constant', wandb_records) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeddb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b208f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc88a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40095e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbd3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
