{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f773258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.8941176470588236, 0.10196078431372549, 0.10980392156862745),\n",
       " (0.21568627450980393, 0.49411764705882355, 0.7215686274509804),\n",
       " (0.30196078431372547, 0.6862745098039216, 0.2901960784313726),\n",
       " (0.596078431372549, 0.3058823529411765, 0.6392156862745098),\n",
       " (1.0, 0.4980392156862745, 0.0),\n",
       " (1.0, 1.0, 0.2),\n",
       " (0.6509803921568628, 0.33725490196078434, 0.1568627450980392),\n",
       " (0.9686274509803922, 0.5058823529411764, 0.7490196078431373),\n",
       " (0.6, 0.6, 0.6))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb\n",
    "api = wandb.Api(timeout=180)\n",
    "import os\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import itertools\n",
    "import  matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import itertools\n",
    "USER='wilderlavington'\n",
    "PROJECT='FunctionalStochasticOptimization'\n",
    "SUMMARY_FILE='sharan_report_0831.csv'\n",
    "import time\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3efa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K=1\n",
    "def smooth(array, k):\n",
    "    array = np.array(array)\n",
    "    new_array = deepcopy(array)\n",
    "    # print(array[max(0,i-k):i] )\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) != 'nan':\n",
    "            avg_list = [val for val in array[max(0,i-k):i+1] if str(val) != 'nan']\n",
    "            new_array[i] = sum(avg_list) / len(avg_list)\n",
    "    return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1176e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataframe(records, id_subfields={}, avg_subfields=['seed'],\n",
    "            max_subfields=['log_eta', 'eta_schedule', 'c'],\n",
    "            x_col='optim_steps', y_col='avg_loss'):\n",
    "    #\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    max_subfields = [m for m in max_subfields if m not in id_subfields.keys()]\n",
    "\n",
    "    for key in id_subfields:\n",
    "        print(key, records[key].unique())\n",
    "        records = records.loc[records[key] == id_subfields[key]]\n",
    "    records['function_evals+grad_evals'] = records['function_evals']+records['grad_evals']\n",
    "    if not len(records):\n",
    "        raise Exception\n",
    "    # remove nans\n",
    "    records = records[records[y_col].notna()]\n",
    "    important_cols = list(set(avg_subfields+max_subfields+\\\n",
    "        list(id_subfields.keys())+[x_col, y_col, 'optim_steps']))\n",
    "    # remove redundant information\n",
    "    records = records[important_cols]\n",
    "    # average over avg_subfields\n",
    "    records = records.drop(avg_subfields, axis=1)\n",
    "    # group over averaging field\n",
    "    gb = list(set(list(max_subfields+list(id_subfields.keys())+[x_col, 'optim_steps'])))\n",
    "    # only look at final optim steps\n",
    "    last_mean_records = records.loc[records['optim_steps'] == records['optim_steps'].max()]\n",
    "    # get the best record\n",
    "    best_record = last_mean_records[last_mean_records[y_col] == last_mean_records[y_col].min()]\n",
    "    # find parameters of the best record\n",
    "    merge_on = list(set(gb)-set(['optim_steps', x_col, y_col]))\n",
    "    merge_on = [ x for x in merge_on if x in best_record.columns.values]\n",
    "    best_records = pd.merge(best_record[merge_on], records, on=merge_on,how='left')\n",
    "    final_records = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].mean()\n",
    "    final_records[y_col+'25'] = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].quantile(0.25)[y_col]\n",
    "    final_records[y_col+'75'] = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].quantile(0.75)[y_col]\n",
    "    final_records = final_records.sort_values(x_col, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "    # smooth outputs \n",
    "    final_records[y_col+'75'] = smooth(final_records[y_col+'75'],K)\n",
    "    final_records[y_col+'25'] = smooth(final_records[y_col+'25'],K)\n",
    "    final_records[y_col] = smooth(final_records[y_col],K)\n",
    "    return final_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(proc_df, x, y, ax, label, linestyle='solid', color=None):\n",
    "    low_order_idx = (torch.tensor(proc_df[x].values) < x_max).nonzero().reshape(-1)\n",
    "    if label:\n",
    "        ax.plot(torch.tensor(proc_df[x].values[low_order_idx]), \n",
    "                torch.tensor(proc_df[y].values[low_order_idx]), \n",
    "                label=label, linestyle=linestyle, color=color,\n",
    "                linewidth=4)\n",
    "    else:\n",
    "        ax.plot(torch.tensor(proc_df[x].values[low_order_idx]), \n",
    "                torch.tensor(proc_df[y].values[low_order_idx]), \n",
    "                label='_nolegend_', linestyle=linestyle, color=color,\n",
    "                linewidth=4)\n",
    "    ax.fill_between(torch.tensor(proc_df[x].values)[low_order_idx],\n",
    "            torch.tensor(proc_df[y+'75'].values)[low_order_idx],\n",
    "            torch.tensor(proc_df[y+'25'].values)[low_order_idx],\n",
    "            alpha = 0.5, label='_nolegend_', linestyle=linestyle, color=color)\n",
    "    return ax\n",
    "\n",
    "def generate_A1_figure(loss, dataset_name):\n",
    "    \n",
    "    # base info   \n",
    "    schedules = ['constant', 'stochastic', 'exponential']\n",
    "    batch_sizes = [25, 125, 625]\n",
    "    m = [1, 2, 5, 10, 20]\n",
    "    x = 'time_elapsed'\n",
    "    y = 'grad_norm'\n",
    "    \n",
    "    # init plots \n",
    "    fig, axs = plt.subplots(SCHEDULES, BATCHES)\n",
    "    colors = mpl.cm.Set1.colors   # Qualitative colormap\n",
    "    colormap = {'SGD':colors[0], 'SLS':colors[1]}.\\\n",
    "        update({'FuncOpt'+str(m_):colors[idx+2] for idx, m_ in enumerate(m)})\n",
    "    fig.title('Comparison of SGD/SLS/FuncOpt: '+loss+'-'+dataset_name)\n",
    "    \n",
    "    # now add in the lines to each of the plots \n",
    "    for row, schedule in enumerate(schedules):\n",
    "        for col, batch_size in enumerate(batch_sizes):\n",
    "            # SLS\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size, 'episodes': episodes,\n",
    "                'use_optimal_stepsize': 1, 'loss': loss, 'algo': 'LSOpt',\n",
    "                'eta_schedule': eta_schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                                             linestyle='dotted', color=colormap['SLS'])\n",
    "            # SGD\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size, 'episodes': episodes,\n",
    "                'use_optimal_stepsize': 1, 'loss': loss, 'algo': 'SGD',\n",
    "                'eta_schedule': eta_schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                                             linestyle='dotted', color=colormap['SGD'])\n",
    "            \n",
    "            # FMDopt theoretical \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': episodes,\n",
    "                        'use_optimal_stepsize': 1,\n",
    "                        'loss': loss, 'algo': 'SGD_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed')\n",
    "                # generate the associated plot \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], \\\n",
    "                                            label, color=colormap['FuncOpt'+str(m_)])\n",
    "            \n",
    "            # FMDopt grid_searched  \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': episodes,\n",
    "                        'use_optimal_stepsize': 0,\n",
    "                        'loss': loss, 'algo': 'SGD_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['log_eta', 'c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed') \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                           linestyle='dotted', color=colormap['FuncOpt'+str(m_)])\n",
    "                ax[row][col].grid()\n",
    "    \n",
    "    # remaining format stuff \n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.rcParams['figure.dpi'] = 400\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    \n",
    "    # show / save\n",
    "    plt.savefig(loss+'_'+dataset_name+'.pdf', bbox_inches='tight')\n",
    "    plt.show() \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "893a0346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_A1_figure(loss, dataset_name):\n",
    "    \n",
    "    # base info   \n",
    "    schedules = ['constant']\n",
    "    batch_sizes = [25, 125, 625]\n",
    "    m = [1, 2, 5, 10, 20]\n",
    "    x = 'time_elapsed'\n",
    "    y = 'grad_norm'\n",
    "    \n",
    "    # init plots \n",
    "    fig, axs = plt.subplots(SCHEDULES, BATCHES)\n",
    "    colors = mpl.cm.Set1.colors   # Qualitative colormap\n",
    "    colormap = {'SGD':colors[0], 'SLS':colors[1]}.\\\n",
    "        update({'FuncOpt'+str(m_):colors[idx+2] for idx, m_ in enumerate(m)})\n",
    "    fig.title('Comparison of Adagrad/Ada-FuncOpt: '+loss+'-'+dataset_name)\n",
    "    \n",
    "    # now add in the lines to each of the plots \n",
    "    for row, schedule in enumerate(schedules):\n",
    "        for col, batch_size in enumerate(batch_sizes):\n",
    "            # Adagrad\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size, 'episodes': episodes,\n",
    "                'use_optimal_stepsize': 1, 'loss': loss, 'algo': 'Adagrad',\n",
    "                'eta_schedule': eta_schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                                             linestyle='dotted', color=colormap['SLS'])\n",
    "             \n",
    "            # FMDopt theoretical \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': episodes,\n",
    "                        'use_optimal_stepsize': 0, 'log_eta': -3, \n",
    "                        'loss': loss, 'algo': 'Ada_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed')\n",
    "                # generate the associated plot \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], \\\n",
    "                                            label, color=colormap['FuncOpt'+str(m_)])\n",
    "            \n",
    "            # FMDopt grid_searched  \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': episodes,\n",
    "                        'use_optimal_stepsize': 0,\n",
    "                        'loss': loss, 'algo': 'Ada_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['log_eta', 'c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed') \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                           linestyle='dotted', color=colormap['FuncOpt'+str(m_)])\n",
    "                ax[row][col].grid()\n",
    "    \n",
    "    # remaining format stuff \n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.rcParams['figure.dpi'] = 400\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    \n",
    "    # show / save\n",
    "    plt.savefig(loss+'_'+dataset_name+'.pdf', bbox_inches='tight')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe00d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
