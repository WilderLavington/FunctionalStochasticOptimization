{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6baa0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb\n",
    "api = wandb.Api(timeout=180)\n",
    "import os\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import itertools\n",
    "import  matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import itertools\n",
    "USER='wilderlavington'\n",
    "PROJECT='FunctionalStochasticOptimization'\n",
    "SUMMARY_FILE='sharan_report_0831.csv'\n",
    "EPISODES = 25000\n",
    "import time\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c758380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K=1\n",
    "def smooth(array, k):\n",
    "    array = np.array(array)\n",
    "    new_array = deepcopy(array)\n",
    "    # print(array[max(0,i-k):i] )\n",
    "    for i in range(len(array)):\n",
    "        if str(array[i]) != 'nan':\n",
    "            avg_list = [val for val in array[max(0,i-k):i+1] if str(val) != 'nan']\n",
    "            new_array[i] = sum(avg_list) / len(avg_list)\n",
    "    return new_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0342d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataframe(records, id_subfields={}, avg_subfields=['seed'],\n",
    "            max_subfields=['log_eta', 'eta_schedule', 'c'],\n",
    "            x_col='optim_steps', y_col='avg_loss'):\n",
    "    #\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    max_subfields = [m for m in max_subfields if m not in id_subfields.keys()]\n",
    "\n",
    "    for key in id_subfields:\n",
    "        print(key, records[key].unique())\n",
    "        records = records.loc[records[key] == id_subfields[key]]\n",
    "    records['function_evals+grad_evals'] = records['function_evals']+records['grad_evals']\n",
    "    if not len(records):\n",
    "        raise Exception\n",
    "    # remove nans\n",
    "    records = records[records[y_col].notna()]\n",
    "    important_cols = list(set(avg_subfields+max_subfields+\\\n",
    "        list(id_subfields.keys())+[x_col, y_col, 'optim_steps']))\n",
    "    # remove redundant information\n",
    "    records = records[important_cols]\n",
    "    # average over avg_subfields\n",
    "    records = records.drop(avg_subfields, axis=1)\n",
    "    # group over averaging field\n",
    "    gb = list(set(list(max_subfields+list(id_subfields.keys())+[x_col, 'optim_steps'])))\n",
    "    # only look at final optim steps\n",
    "    last_mean_records = records.loc[records['optim_steps'] == records['optim_steps'].max()]\n",
    "    # get the best record\n",
    "    best_record = last_mean_records[last_mean_records[y_col] == last_mean_records[y_col].min()]\n",
    "    # find parameters of the best record\n",
    "    merge_on = list(set(gb)-set(['optim_steps', x_col, y_col]))\n",
    "    merge_on = [ x for x in merge_on if x in best_record.columns.values]\n",
    "    best_records = pd.merge(best_record[merge_on], records, on=merge_on,how='left')\n",
    "    final_records = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].mean()\n",
    "    final_records[y_col+'25'] = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].quantile(0.25)[y_col]\n",
    "    final_records[y_col+'75'] = best_records.groupby(merge_on+[x_col], as_index=False)[y_col].quantile(0.75)[y_col]\n",
    "    final_records = final_records.sort_values(x_col, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "    # smooth outputs \n",
    "    final_records[y_col+'75'] = smooth(final_records[y_col+'75'],K)\n",
    "    final_records[y_col+'25'] = smooth(final_records[y_col+'25'],K)\n",
    "    final_records[y_col] = smooth(final_records[y_col],K)\n",
    "    return final_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40461507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(proc_df, x, y, ax, label, linestyle='solid', color=None):\n",
    "    low_order_idx = (torch.tensor(proc_df[x].values) < x_max).nonzero().reshape(-1)\n",
    "    if label:\n",
    "        ax.plot(torch.tensor(proc_df[x].values[low_order_idx]), \n",
    "                torch.tensor(proc_df[y].values[low_order_idx]), \n",
    "                label=label, linestyle=linestyle, color=color,\n",
    "                linewidth=4)\n",
    "    else:\n",
    "        ax.plot(torch.tensor(proc_df[x].values[low_order_idx]), \n",
    "                torch.tensor(proc_df[y].values[low_order_idx]), \n",
    "                label='_nolegend_', linestyle=linestyle, color=color,\n",
    "                linewidth=4)\n",
    "    ax.fill_between(torch.tensor(proc_df[x].values)[low_order_idx],\n",
    "            torch.tensor(proc_df[y+'75'].values)[low_order_idx],\n",
    "            torch.tensor(proc_df[y+'25'].values)[low_order_idx],\n",
    "            alpha = 0.5, label='_nolegend_', linestyle=linestyle, color=color)\n",
    "    return ax\n",
    "\n",
    "def generate_A1_figure(loss, dataset_name):\n",
    "    \n",
    "    # base info   \n",
    "    schedules = ['constant', 'stochastic', 'exponential']\n",
    "    batch_sizes = [25, 125, 625]\n",
    "    m = [1, 2, 5, 10, 20]\n",
    "    x = 'time_elapsed'\n",
    "    y = 'grad_norm'\n",
    "    \n",
    "    # init plots \n",
    "    fig, axs = plt.subplots(SCHEDULES, BATCHES)\n",
    "    colors = mpl.cm.Set1.colors   # Qualitative colormap\n",
    "    colormap = {'SGD':colors[0], 'SLS':colors[1]}.\\\n",
    "        update({'FuncOpt'+str(m_):colors[idx+2] for idx, m_ in enumerate(m)})\n",
    "    fig.title('Comparison of SGD/SLS/FuncOpt: '+loss+'-'+dataset_name)\n",
    "    \n",
    "    # now add in the lines to each of the plots \n",
    "    for row, schedule in enumerate(schedules):\n",
    "        for col, batch_size in enumerate(batch_sizes):\n",
    "            # SLS\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size, 'episodes': EPISODES,\n",
    "                'use_optimal_stepsize': 1, 'loss': loss, 'algo': 'LSOpt',\n",
    "                'eta_schedule': eta_schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                                             linestyle='dotted', color=colormap['SLS'])\n",
    "            # SGD\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size, 'episodes': EPISODES,\n",
    "                'use_optimal_stepsize': 1, 'loss': loss, 'algo': 'SGD',\n",
    "                'eta_schedule': eta_schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                                             linestyle='dotted', color=colormap['SGD'])\n",
    "            \n",
    "            # FMDopt theoretical \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': EPISODES,\n",
    "                        'use_optimal_stepsize': 1,\n",
    "                        'loss': loss, 'algo': 'SGD_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed')\n",
    "                # generate the associated plot \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], \\\n",
    "                                            label, color=colormap['FuncOpt'+str(m_)])\n",
    "            \n",
    "            # FMDopt grid_searched  \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': EPISODES,\n",
    "                        'use_optimal_stepsize': 0,\n",
    "                        'loss': loss, 'algo': 'SGD_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['log_eta', 'c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed') \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                           linestyle='dotted', color=colormap['FuncOpt'+str(m_)])\n",
    "                ax[row][col].grid()\n",
    "    \n",
    "    # remaining format stuff \n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.rcParams['figure.dpi'] = 400\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    \n",
    "    # show / save\n",
    "    plt.savefig(loss+'_'+dataset_name+'.pdf', bbox_inches='tight')\n",
    "    plt.show() \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1557ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_A2_figure(loss, dataset_name):\n",
    "    \n",
    "    # base info   \n",
    "    schedules = ['constant']\n",
    "    batch_sizes = [25, 125, 625]\n",
    "    m = [1, 2, 5, 10, 20]\n",
    "    x = 'time_elapsed'\n",
    "    y = 'grad_norm'\n",
    "    \n",
    "    # init plots \n",
    "    fig, axs = plt.subplots(SCHEDULES, BATCHES)\n",
    "    colors = mpl.cm.Set1.colors   # Qualitative colormap\n",
    "    colormap = {'SGD':colors[0], 'SLS':colors[1]}.\\\n",
    "        update({'FuncOpt'+str(m_):colors[idx+2] for idx, m_ in enumerate(m)})\n",
    "    fig.title('Comparison of Adagrad/Ada-FuncOpt: '+loss+'-'+dataset_name)\n",
    "    \n",
    "    # now add in the lines to each of the plots \n",
    "    for row, schedule in enumerate(schedules):\n",
    "        for col, batch_size in enumerate(batch_sizes):\n",
    "            # Adagrad\n",
    "            proc_df = format_dataframe(wandb_records,\n",
    "                id_subfields={'batch_size': batch_size, 'episodes': EPISODES,\n",
    "                'use_optimal_stepsize': 1, 'loss': loss, 'algo': 'Adagrad',\n",
    "                'eta_schedule': eta_schedule, 'dataset_name': dataset_name},\n",
    "                x_col=x , y_col=y) \n",
    "            ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                                             linestyle='dotted', color=colormap['SLS'])\n",
    "             \n",
    "            # FMDopt theoretical \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': EPISODES,\n",
    "                        'use_optimal_stepsize': 0, 'log_eta': -3, \n",
    "                        'loss': loss, 'algo': 'Ada_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed')\n",
    "                # generate the associated plot \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], \\\n",
    "                                            label, color=colormap['FuncOpt'+str(m_)])\n",
    "            \n",
    "            # FMDopt grid_searched  \n",
    "            for m_ in m:\n",
    "                # create parsed info \n",
    "                proc_df = format_dataframe(records, \n",
    "                    id_subfields={'batch_size': batch_size, 'episodes': EPISODES,\n",
    "                        'use_optimal_stepsize': 0,\n",
    "                        'loss': loss, 'algo': 'Ada_FMDOpt', 'm': m_,\n",
    "                        'eta_schedule': eta_schedule, 'dataset_name': dataset_name}, \n",
    "                         avg_subfields=['seed'], max_subfields=['log_eta', 'c'],\n",
    "                    x_col='grad_norm', y_col='time_elapsed') \n",
    "                ax[row][col] = generate_plot(proc_df, x, y, ax[row][col], label=None, \n",
    "                           linestyle='dotted', color=colormap['FuncOpt'+str(m_)])\n",
    "                ax[row][col].grid()\n",
    "    \n",
    "    # remaining format stuff \n",
    "    fig.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.yscale(\"log\")\n",
    "    plt.rcParams['figure.dpi'] = 400\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    \n",
    "    # show / save\n",
    "    plt.savefig('Adaptive_'+loss+'_'+dataset_name+'.pdf', bbox_inches='tight')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = ['mushrooms', 'ijcnn', 'rcv1']\n",
    "losses = ['MSELoss', 'BCEWithLogitsLoss']\n",
    "wandb_records = pd.read_csv('logs/wandb_data/__full__'+SUMMARY_FILE, header=0, squeeze=True)\n",
    "for data_set in data_sets:\n",
    "    for loss in losses:\n",
    "        print('generating SGD plot for ', data_set, loss)\n",
    "        generate_A1_figure(loss, data_set)\n",
    "        print('generating Adagrad plot for ', data_set, loss)\n",
    "        generate_A2_figure(loss, dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
